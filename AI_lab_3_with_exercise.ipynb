{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Artificial Intelligence - Lab 3"
      ],
      "metadata": {
        "id": "JvtOrzgBKYWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this laboratory we will explore a real classification problem involving high dimensional data (images). We will use the popular [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, which contains 70.000 images of handwritten digits, annotated with the corresponding labels (from 0 to 9).\n",
        "\n",
        "For solving this problem we will implement a ***deep learning*** architecture, that is, a MLP with several hidden layers. We will also implement a convolutional neural network, specifically suited for image processing.\n",
        "\n",
        "Finally, we will explore how to simulate a perceptual experimental task, by testing the model's robustness to noise injected in the visual stimuli."
      ],
      "metadata": {
        "id": "Rb-uqCAXyNwE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cc7QAjS7HQM8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Lambda"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MNIST is already split into training / test sets, so we don't need to use `train_test_split`. It is also already divided between input data (pixels) and output targets (digit classes)."
      ],
      "metadata": {
        "id": "Xm-VEVBvKT1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "mnist_tr = MNIST(root=\"../mnist\", train=True, download=True)\n",
        "mnist_te = MNIST(root=\"../mnist\", train=False, download=True)"
      ],
      "metadata": {
        "id": "yUpfMz0zLG1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_tr, mnist_tr_labels = mnist_tr.data.numpy(), mnist_tr.targets.numpy()\n",
        "mnist_te, mnist_te_labels = mnist_te.data.numpy(), mnist_te.targets.numpy()"
      ],
      "metadata": {
        "id": "D9Y1dzMXLO0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The images are in a two dimensional format (28x28 matrices). However, the fully-connected MLP neural network requires one dimensional input vectors, thus the first step is to flatten the matrices with the function `reshape`, obtaining a vector of 784 elements.\n",
        "\n",
        "Moreover, the images are saved in a conventional format, where each pixel can assume values between 0 and 255. Hence, the second step is to normalize such values to a 0-1 interval, simply by dividing by 255."
      ],
      "metadata": {
        "id": "Oak2OZQnzYQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr = mnist_tr.reshape(60000, 28 * 28)\n",
        "x_te = mnist_te.reshape(10000, 28 * 28)"
      ],
      "metadata": {
        "id": "TgiPM3v2NI6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr = x_tr / 255\n",
        "x_te = x_te / 255"
      ],
      "metadata": {
        "id": "GYsSs5H-NZk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize the first test pattern:"
      ],
      "metadata": {
        "id": "QZBb6C3oL7sq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plt.imshow(x_te[0].reshape(28, 28), cmap=\"gray\")"
      ],
      "metadata": {
        "id": "OTusTZjhL69w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create one MLP with two hidden layers, keeping the learning parameters to the default setting. Then, we can start the training."
      ],
      "metadata": {
        "id": "5jRiUD5E0Ng3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# with 10 iterations the convergence is already good enough and the algorithm\n",
        "# takes approximately three minutes to run. For a better convergence it is\n",
        "# possible to increase the number of iterations.\n",
        "\n",
        "MLP = MLPClassifier(hidden_layer_sizes=(500, 500),\n",
        "                    max_iter = 10,\n",
        "                    random_state=42)"
      ],
      "metadata": {
        "id": "RwcXBG18Mhbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLP = MLP.fit(x_tr, mnist_tr_labels)"
      ],
      "metadata": {
        "id": "c7tdXY6QM_W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can proceed by plotting the error curve, the mean accuracy and the confusion matrix."
      ],
      "metadata": {
        "id": "xs0jfuxF0ofa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plt.plot(range(MLP.n_iter_), MLP.loss_curve_)\n",
        "_ = plt.xlabel(\"Epoch\")\n",
        "_ = plt.ylabel(\"Loss\")\n",
        "_ = plt.title(\"Loss minimization during training\")"
      ],
      "metadata": {
        "id": "4ID8BtSHOJmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MLP.score(x_te, mnist_te_labels)"
      ],
      "metadata": {
        "id": "3jIQT9ThNz8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_te_predictions = MLP.predict(x_te)\n",
        "_ = metrics.ConfusionMatrixDisplay.from_predictions(mnist_te_labels, x_te_predictions)"
      ],
      "metadata": {
        "id": "FQ_v-w2QOjzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EXERCISE: Study robustness to noise.**\n",
        "\n",
        "*Tip #1: You can inject noise into the test images by adding a (Gaussian) random matrix to the input vectors using the np.random.normal function.*\n",
        "\n",
        "*Tip #2: You can define the strength of the noise by changing the standard deviation of the Gaussian.*\n",
        "\n",
        "*Tip #3: You can either directly add the noise to the entire dataset matrix, or you can add it to each individual image (in this case, you'll need a for loop).*\n",
        "\n",
        "*Tip #4: Visualize the noisy images using the plt.imshow function, and compute the accuracy using the MLP.score function.*"
      ],
      "metadata": {
        "id": "b-3tAtcPqxWn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wWTuRstiQoTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network\n",
        "\n",
        "Using a high-level Python framework (TensorFlow) we can even \"easily\" implement a more sophisticated Convolutional Neural Network!"
      ],
      "metadata": {
        "id": "zqKH93-qqpth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "rZADr-f2kXET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential(\n",
        "    [keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
        "     keras.layers.Flatten(),\n",
        "     keras.layers.Dense(units=10, activation='softmax')]\n",
        ")\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              metrics=[\"accuracy\"],\n",
        "              loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "lpT6yPD6kZCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Differently from fully-connected MLP, convolutional networks require 2D images as input:"
      ],
      "metadata": {
        "id": "5ZIKc35VRh17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr_conv = x_tr.reshape(-1, 28, 28, 1)\n",
        "x_te_conv = x_te.reshape(-1, 28, 28, 1)"
      ],
      "metadata": {
        "id": "sRad8og0m1h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_trend = model.fit(x_tr_conv, mnist_tr_labels, epochs=10)"
      ],
      "metadata": {
        "id": "jdBTAZ_vlyhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = plt.plot(range(10), loss_trend.history['loss'])\n",
        "_ = plt.xlabel(\"Epoch\")\n",
        "_ = plt.ylabel(\"Loss\")\n",
        "_ = plt.title(\"Loss minimization during training\")"
      ],
      "metadata": {
        "id": "HQpbbZ0Opv0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_te_conv, mnist_te_labels)"
      ],
      "metadata": {
        "id": "aFQ_8Ymzn2o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ = x_te_predictions_conv = model.predict(x_te_conv)\n",
        "metrics.ConfusionMatrixDisplay.from_predictions(mnist_te_labels, x_te_predictions_conv.argmax(axis=1))"
      ],
      "metadata": {
        "id": "yYpVY-4_sjJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Robustness to noise"
      ],
      "metadata": {
        "id": "s4iNci98q3-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_te_noisy_conv = x_te_noisy.reshape(-1, 28, 28, 1)\n",
        "test_loss, test_accuracy = model.evaluate(x_te_noisy_conv, mnist_te_labels)"
      ],
      "metadata": {
        "id": "5LIWjCLfTsmq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}